import httpx
from config import settings
from typing import Optional

class OllamaService:
    def __init__(self):
        self.base_url = settings.OLLAMA_BASE_URL
        self.model = settings.OLLAMA_MODEL
    
    async def generate(self, prompt: str, system_prompt: Optional[str] = None) -> str:
        """Generate text using Ollama API"""
        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        messages.append({"role": "user", "content": prompt})
        
        try:
            # Connect timeout 3s, Read timeout 120s (for generation)
            async with httpx.AsyncClient(timeout=httpx.Timeout(120.0, connect=3.0)) as client:
                response = await client.post(
                    f"{self.base_url}/api/chat",
                    json={
                        "model": self.model,
                        "messages": messages,
                        "stream": False
                    }
                )
                response.raise_for_status()
                data = response.json()
                return data.get("message", {}).get("content", "")
        except Exception as e:
            # Fallback response if Ollama is not available
            print(f"Ollama Error: {e}")
            return "Unable to connect to AI"
    
    async def analyze_mood(self, mood_text: str) -> dict:
        """Analyze user's mood and generate encouragement"""
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ¸©æš–ä½“è´´çš„æƒ…ç»ªåŠ©ç†ã€‚ç”¨æˆ·ä¼šå‘Šè¯‰ä½ ä»–ä»¬çš„å¿ƒæƒ…ã€‚
è¯·ç”¨ä»¥ä¸‹JSONæ ¼å¼å›å¤ï¼ˆåªå›å¤JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ï¼‰ï¼š
{
    "encouragement": "é¼“åŠ±å’Œå®‰æ…°çš„è¯è¯­ï¼ˆ100-150å­—ï¼‰",
    "suggestion": "ç»™ç”¨æˆ·çš„å»ºè®®ï¼ˆ50-80å­—ï¼‰",
    "emoji": "ä¸€ä¸ªæœ€é€‚åˆçš„è¡¨æƒ…ç¬¦å·",
    "mood_score": æƒ…ç»ªåˆ†æ•°ä»-1åˆ°1çš„æ•°å­—
}"""
        
        response = await self.generate(mood_text, system_prompt)
        try:
            import json
            # Try to parse JSON from response
            start = response.find("{")
            end = response.rfind("}") + 1
            if start != -1 and end > start:
                return json.loads(response[start:end])
        except:
            pass
        
        # Fallback Mock Response (looks real)
        return {
            "encouragement": "æ„Ÿå—åˆ°ä½ çš„å¿ƒæƒ…äº†ã€‚æ— è®ºæ­¤åˆ»æ˜¯é˜´é›¨è¿˜æ˜¯æ™´å¤©ï¼Œè¯·è®°ä½ï¼Œæ‰€æœ‰çš„æƒ…ç»ªéƒ½æ˜¯ç”Ÿå‘½æµåŠ¨çš„è¯æ˜ã€‚ç»™è‡ªå·±ä¸€ä¸ªæ¸©æš–çš„æ‹¥æŠ±ï¼Œä½ åšå¾—å¾ˆæ£’äº†ã€‚",
            "suggestion": "ä¹Ÿè®¸å¯ä»¥å°è¯•æ·±å‘¼å¸ä¸‰æ¬¡ï¼Œæˆ–è€…å¬ä¸€é¦–èˆ’ç¼“çš„éŸ³ä¹ï¼Œè®©è‡ªå·±æ…¢æ…¢æ”¾æ¾ä¸‹æ¥ã€‚",
            "emoji": "ğŸŒ¿",
            "mood_score": 0.5
        }
    
    async def analyze_love_chat(self, chat_content: str) -> dict:
        """Analyze chat and suggest better replies"""
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ‹çˆ±æ•™ç»ƒã€‚ç”¨æˆ·ä¼šå‘é€ä»–ä»¬çš„èŠå¤©è®°å½•ã€‚
è¯·åˆ†æå¯¹è¯å¹¶ç”¨ä»¥ä¸‹JSONæ ¼å¼å›å¤ï¼ˆåªå›å¤JSONï¼‰ï¼š
{
    "analysis": "å¯¹å½“å‰å¯¹è¯çŠ¶æ€çš„åˆ†æï¼ˆ80-120å­—ï¼‰",
    "suggestions": ["å»ºè®®å›å¤1", "å»ºè®®å›å¤2", "å»ºè®®å›å¤3"],
    "tips": "æé«˜å¥½æ„Ÿåº¦çš„æŠ€å·§ï¼ˆ50-80å­—ï¼‰",
    "affection_score": å½“å‰å¥½æ„Ÿåº¦é¢„ä¼°0-100
}"""
        
        response = await self.generate(chat_content, system_prompt)
        try:
            import json
            start = response.find("{")
            end = response.rfind("}") + 1
            if start != -1 and end > start:
                return json.loads(response[start:end])
        except:
            pass
        
        return {
            "analysis": response,
            "suggestions": ["ä»Šå¤©æ€ä¹ˆæ ·ï¼Ÿ", "æƒ³ä½ äº†~", "æœ‰ç©ºä¸€èµ·åƒé¥­å—ï¼Ÿ"],
            "tips": "ä¿æŒçœŸè¯šï¼Œå±•ç°å…³å¿ƒã€‚",
            "affection_score": 50
        }
    
    async def reflect_diary(self, diary_content: str) -> dict:
        """Generate self-reflection analysis"""
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ¸©æŸ”çš„å¿ƒç†é¡¾é—®ï¼Œå¸®åŠ©ç”¨æˆ·è¿›è¡Œè‡ªæˆ‘åçœã€‚
ç”¨æˆ·ä¼šåˆ†äº«ä»Šå¤©çš„ä¸€å¥è¯æˆ–æƒ³æ³•ã€‚
è¯·ç”¨ä»¥ä¸‹JSONæ ¼å¼å›å¤ï¼ˆåªå›å¤JSONï¼‰ï¼š
{
    "reflection": "æ·±å…¥çš„åæ€åˆ†æï¼ˆ100-150å­—ï¼‰",
    "growth_insight": "æˆé•¿æ´å¯Ÿï¼ˆ80-100å­—ï¼‰",
    "tomorrow_suggestion": "æ˜å¤©å¯ä»¥å°è¯•çš„ä¸€ä»¶äº‹",
    "growth_score": è‡ªæˆ‘æˆé•¿è¯„åˆ†0-100
}"""
        
        response = await self.generate(diary_content, system_prompt)
        try:
            import json
            start = response.find("{")
            end = response.rfind("}") + 1
            if start != -1 and end > start:
                return json.loads(response[start:end])
        except:
            pass
        
        return {
            "reflection": response,
            "growth_insight": "æ¯ä¸€å¤©éƒ½æ˜¯æˆé•¿çš„æœºä¼šã€‚",
            "tomorrow_suggestion": "å°è¯•åšä¸€ä»¶è®©è‡ªå·±å¼€å¿ƒçš„äº‹ã€‚",
            "growth_score": 70
        }
    
    async def interpret_tarot(self, cards: list, question: str = "") -> str:
        """Interpret tarot cards with AI"""
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªç¥ç§˜è€Œæ¸©æš–çš„å¡”ç½—ç‰Œå åœå¸ˆã€‚
è¯·æ ¹æ®æŠ½åˆ°çš„ç‰Œä¸ºç”¨æˆ·è¿›è¡Œè§£è¯»ï¼Œè¯­æ°”è¦ç¥ç§˜ä½†å……æ»¡å¸Œæœ›å’Œå®‰æ…°ã€‚
è§£è¯»è¦å…·ä½“ï¼Œç»“åˆç”¨æˆ·çš„é—®é¢˜ï¼ˆå¦‚æœæœ‰ï¼‰ï¼Œç»™å‡ºå®é™…çš„å»ºè®®ã€‚
å›å¤é•¿åº¦200-300å­—ã€‚"""
        
        prompt = f"ç”¨æˆ·çš„é—®é¢˜ï¼š{question if question else 'è¯·ä¸ºæˆ‘å åœ'}\næŠ½åˆ°çš„ç‰Œï¼š{', '.join(cards)}"
        return await self.generate(prompt, system_prompt)
    
    async def voice_companion(self, user_message: str) -> str:
        """Voice companion chat response"""
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ¸©æš–çš„è¯­éŸ³é™ªä¼´åŠ©ç†ï¼Œåå«å°å¡”ã€‚
ç”¨æˆ·å¯èƒ½æ„Ÿåˆ°å­¤ç‹¬ï¼Œéœ€è¦æœ‰äººé™ªä¼´èŠå¤©ã€‚
è¯·ç”¨æ¸©æš–ã€å…³å¿ƒçš„è¯­æ°”å›å¤ï¼Œåƒä¸€ä¸ªè´´å¿ƒçš„æœ‹å‹ã€‚
å›å¤è¦ç®€çŸ­è‡ªç„¶ï¼ˆ50-100å­—ï¼‰ï¼Œé€‚åˆè¯­éŸ³æœ—è¯»ã€‚"""
        
        return await self.generate(user_message, system_prompt)


ollama_service = OllamaService()
